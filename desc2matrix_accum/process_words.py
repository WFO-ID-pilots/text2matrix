from typing import Set, List
import nltk
import re
import inflect

nltk.download('punkt')
nltk.download('stopwords')
nltk.download('averaged_perceptron_tagger')
from nltk.corpus import stopwords

inf = inflect.engine()
# Turn on 'classical' plurals as they are likely to occur in the dataset
inf.classical()

def get_word_set(descstr:str) -> Set[str]:
    """
    Get the set of words in a given string

    Paramters:
        descstr (str): The string to extract non-stop words from
    
    Returns:
        descset (Set[str]): The set of non-stop words in the provided string
    """

    # Gather stop words
    stop_words = set(stopwords.words('english'))

    # Insert whitespace before/after period, comma, colon, semicolon and brackets
    descstr = re.sub(r'[^0-9] *\. *[^0-9]', '. ', descstr) # Do not substitute periods in floating-point numbers
    descstr = re.sub(r'[^0-9] *\. *[0-9]', '. ', descstr) # Substitute periods next to numbers if either side is not a number
    descstr = re.sub(r'[0-9] *\. *[^0-9]', '. ', descstr)
    descstr = re.sub(r' *, *', ', ', descstr)
    descstr = re.sub(r' *: *', ': ', descstr)
    descstr = re.sub(r' *; *', '; ', descstr)
    descstr = re.sub(r' *\( *', ' (', descstr)
    descstr = re.sub(r' *\) *', ') ', descstr)

    # Collapse numeric ranges to single 'word' to check for presence
    descstr = re.sub(r'([0-9]) *- *([0-9])', r'\1-\2', descstr)

    # Tokenise words, remove stop words, convert to lowercase
    descset = set([w.lower() for w in nltk.word_tokenize(descstr) if not w.lower() in stop_words])

    # Remove punctuations & brackets
    descset = descset.difference({'.', ',', ':', ';', '“', '”', '"', "'", "(", ")"})

    # Singularise nouns (duplicates will automatically be merged since this is a set)
    descset_n = set([w for w in descset
                     if nltk.pos_tag([w])[0][1] in ['NN', 'NNS', 'NNPS', 'NNP']])
    descset_sing_n = set([w if inf.singular_noun(w) == False else inf.singular_noun(w) # inflection may determine that the word is not a noun, in which case use the original word
                          for w in descset_n])
    descset = descset.difference(descset_n).union(descset_sing_n) # Remove nouns and add back singulars

    # Return word set
    return descset

# Identify omitted words in char_json given the original description
def get_omissions(desc:str, char_json:List[dict]) -> Set[str]:
    """
    Identify omitted words in a char_json output from the desc2charjson functions given the original species description

    Parameters:
        desc (str): The original species description to compare the JSON output against
        char_json (dict): The list of characteristics generated by a desc2charjson function, structured as [{'characteristic': '', 'value': ''}, ...]
    
    Returns:
        omissions (Set[str]): The set of words that were omitted in the JSON output
    """

    # Compile names of characteristics and their corresponding values to a single string
    compiled_charstr = '\n'.join(['{}: {}'.format(char['characteristic'], char['value']) for char in char_json])

    # Feed string into get_word_set to get the set of words
    out_words = get_word_set(compiled_charstr)
    # Feed the original description into get_word_set to get the set of words
    desc_words = get_word_set(desc)

    # Determine omitted words
    omissions = desc_words.difference(out_words)

    # Return set of omitted words
    return omissions